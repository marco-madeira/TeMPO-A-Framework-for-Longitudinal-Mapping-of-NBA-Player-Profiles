{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e31bafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pandas is already installed.\n",
      "✅ numpy is already installed.\n",
      "✅ scikit-learn is already installed.\n",
      "✅ scipy is already installed.\n",
      "✅ umap-learn is already installed.\n",
      "✅ matplotlib is already installed.\n",
      "✅ seaborn is already installed.\n",
      "✅ plotly is already installed.\n",
      "✅ nbformat is already installed.\n"
     ]
    }
   ],
   "source": [
    "%run ./Imports.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb53f6",
   "metadata": {},
   "source": [
    "#### Removal of players with low minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaae842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Plots the cumulative distribution function (CDF) of a specific column.\n",
    "# The function highlights a reference cut-off line at 400 (can be changed if needed).\n",
    "\n",
    "def cdf_graph(dataset: pd.DataFrame, column: str, title: str):\n",
    "    \n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.ecdfplot(data=dataset, x=column, log_scale=(True, False))\n",
    "\n",
    "    plt.axvline(400, color='red', linestyle='--', label='Cut-off Point')\n",
    "\n",
    "    plt.xlabel('Minutes')\n",
    "    plt.ylabel('Percentage')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"{title}.png\", format=\"png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb55c8",
   "metadata": {},
   "source": [
    "#### High correlations features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c21a4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_of_correlation_graph(df: pd.DataFrame, columns: list[str] = []):\n",
    "\n",
    "    # Plots a correlation heatmap for the selected columns of a DataFrame.\n",
    "    # If no columns are provided, the heatmap uses all columns.\n",
    "    # In our case column names are renamed for readability and abbreviated for shot types.\n",
    "\n",
    "    filtered_df = df[columns] if columns else df\n",
    "\n",
    "    filtered_df = filtered_df.rename(\n",
    "        columns=lambda x: x.replace(\"_MEAN\", \"\")\n",
    "                          .replace(\"_\", \" \")\n",
    "                          .replace(\"CLOSE SHOT\", \"CS\")\n",
    "                          .replace(\"MID RANGE SHOT\", \"MRS\")\n",
    "                          .replace(\"LONG\", \"L\")\n",
    "                          .replace(\"THREE POINT SHOT\", \"TPS\")\n",
    "    )\n",
    "\n",
    "    corr = filtered_df.corr()\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    ax = sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        annot_kws={\"size\": 4},\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"coolwarm\",\n",
    "        xticklabels=True,\n",
    "        yticklabels=True,\n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=8, rotation=90)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=8, rotation=0)\n",
    "\n",
    "    legend_patches = [\n",
    "        mpatches.Patch(color=\"white\", label=\"CS = Close Shot\"),\n",
    "        mpatches.Patch(color=\"white\", label=\"MRS = Mid Range Shot\"),\n",
    "        mpatches.Patch(color=\"white\", label=\"L MRS = Long Mid Range Shot\"),\n",
    "        mpatches.Patch(color=\"white\", label=\"TPS = Three Point Shot\"),\n",
    "    ]\n",
    "\n",
    "    plt.legend(\n",
    "        handles=legend_patches,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.15),\n",
    "        frameon=False,\n",
    "        ncol=2,\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "042e3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_loadings(df: pd.DataFrame, selected_columns, output_file: str = \"pca_plot.png\"):\n",
    "\n",
    "    # Plots the PCA loadings of selected features on the first two principal components (PC1 and PC2).\n",
    "    # In our case, features are grouped by type (e.g., CLOSE_SHOT, MID_RANGE_SHOT) and styled with different colors/markers.\n",
    "    # The selected features are highlighted, must change if using other group of features.\n",
    "\n",
    "    style_rules = {\n",
    "        \"CLOSE_SHOT\": {\"color\": \"red\", \"marker\": \"o\"},\n",
    "        \"MID_RANGE_SHOT\": {\"color\": \"green\", \"marker\": \"s\"},\n",
    "        \"LONG_MID_RANGE_SHOT\": {\"color\": \"orange\", \"marker\": \"D\"},\n",
    "        \"THREE_POINT_SHOT\": {\"color\": \"blue\", \"marker\": \"^\"}\n",
    "    }\n",
    "\n",
    "    highlighted_features = [\n",
    "        \"CLOSE_SHOT_M_MEAN\",\n",
    "        \"MID_RANGE_SHOT_U_MEAN\",\n",
    "        \"LONG_MID_RANGE_SHOT_M_MEAN\",\n",
    "        \"CLOSE_SHOT_PCT_MEAN\",\n",
    "        \"MID_RANGE_SHOT_PCT_MEAN\",\n",
    "    ]\n",
    "\n",
    "    abbreviations = {\n",
    "        \"CLOSE_SHOT_M_MEAN\": \"CS M\",\n",
    "        \"MID_RANGE_SHOT_U_MEAN\": \"MRS U\",\n",
    "        \"LONG_MID_RANGE_SHOT_M_MEAN\": \"L MRS M\",\n",
    "        \"CLOSE_SHOT_PCT_MEAN\": \"CS PCT\",\n",
    "        \"MID_RANGE_SHOT_PCT_MEAN\": \"MRS PCT\",\n",
    "    }\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(df[selected_columns])\n",
    "    pca = PCA()\n",
    "    pca.fit(X_scaled)\n",
    "    loadings = pca.components_.T\n",
    "\n",
    "    df_loadings = pd.DataFrame({\n",
    "        \"Variable\": selected_columns,\n",
    "        \"PC1\": loadings[:, 0],\n",
    "        \"PC2\": loadings[:, 1]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.axhline(0, color=\"gray\", linewidth=0.8, linestyle=\"--\")\n",
    "    plt.axvline(0, color=\"gray\", linewidth=0.8, linestyle=\"--\")\n",
    "\n",
    "    for group, style in style_rules.items():\n",
    "        subset = df_loadings[df_loadings[\"Variable\"].str.startswith(group)]\n",
    "        for _, row in subset.iterrows():\n",
    "            var, x, y = row[\"Variable\"], row[\"PC1\"], row[\"PC2\"]\n",
    "            print(f\"{var}: PC1={x:.4f}, PC2={y:.4f}\")\n",
    "\n",
    "            if var in highlighted_features:\n",
    "                plt.scatter(\n",
    "                    x, y,\n",
    "                    s=35,\n",
    "                    color=style[\"color\"],\n",
    "                    marker=style[\"marker\"],\n",
    "                    edgecolor=\"black\",\n",
    "                    linewidths=1,\n",
    "                    alpha=0.75\n",
    "                )\n",
    "                plt.text(\n",
    "                    x - 0.003, y,\n",
    "                    abbreviations.get(var, var),\n",
    "                    fontsize=10,\n",
    "                    ha=\"right\",\n",
    "                    va=\"center\"\n",
    "                )\n",
    "            else:\n",
    "                plt.scatter(\n",
    "                    x, y,\n",
    "                    s=30,\n",
    "                    color=style[\"color\"],\n",
    "                    marker=style[\"marker\"],\n",
    "                    edgecolor=\"none\",\n",
    "                    alpha=0.75\n",
    "                )\n",
    "\n",
    "    handles = [\n",
    "        plt.Line2D(\n",
    "            [0], [0],\n",
    "            marker=style[\"marker\"],\n",
    "            color=\"w\",\n",
    "            markerfacecolor=style[\"color\"],\n",
    "            markersize=10,\n",
    "            label=group\n",
    "        )\n",
    "        for group, style in style_rules.items()\n",
    "    ]\n",
    "\n",
    "    plt.legend(\n",
    "        handles=handles,\n",
    "        fontsize=8,\n",
    "        ncol=2,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.15),\n",
    "        frameon=False,\n",
    "        handlelength=1,\n",
    "        handletextpad=1,\n",
    "        columnspacing=1,\n",
    "        labelspacing=0.8\n",
    "    )\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(False)\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe0117",
   "metadata": {},
   "source": [
    "#### Heavy Tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "567137c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a DataFrame with mean, standard deviation, coefficient of variation, quartiles, median, kurtosis, and skewness for each numeric feature.\n",
    "# Non-numeric columns are ignored.\n",
    "# Useful for quick descriptive analysis before modeling or visualization.\n",
    "\n",
    "def summarize_features(df: pd.DataFrame):\n",
    "\n",
    "    mean_vals = df.mean(numeric_only=True)\n",
    "    std_vals = df.std(numeric_only=True)\n",
    "\n",
    "    summary_stats = pd.DataFrame({\n",
    "        'Mean': mean_vals,\n",
    "        'Standard Deviation': std_vals,\n",
    "        'Coefficient of Variation': std_vals / mean_vals,\n",
    "        'Q1 (25%)': df.quantile(0.25, numeric_only=True),\n",
    "        'Median (50%)': df.quantile(0.50, numeric_only=True),\n",
    "        'Q3 (75%)': df.quantile(0.75, numeric_only=True),\n",
    "        'Kurtosis': df.kurtosis(numeric_only=True),\n",
    "        'Skewness': df.skew(numeric_only=True),\n",
    "    })\n",
    "\n",
    "    summary_stats.to_csv(\"summarized_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a28d90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms_in_batches(df: pd.DataFrame, batch_size: int = 10, output_prefix: str = 'histograms'):\n",
    "\n",
    "    # Plots histograms for numeric columns of a DataFrame in batches.\n",
    "    # Useful for exploratory data analysis to visualize feature distributions.\n",
    "\n",
    "    num_cols = len(df.columns)\n",
    "\n",
    "    for i in range(0, num_cols, batch_size):\n",
    "        batch_cols = df.columns[i:i + batch_size]\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # NOTE: Plot each feature in the batch\n",
    "        for j, col in enumerate(batch_cols, 1):\n",
    "            plt.subplot(2, 5, j)  # 2 rows, 5 columns layout for up to 10 features\n",
    "            df[col].hist(bins=30, edgecolor='black')\n",
    "            plt.title(col)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f'{output_prefix}_{i}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b577c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_skewed_features(df: pd.DataFrame, skew_threshold: float = 1) -> pd.DataFrame:\n",
    "\n",
    "    # Detects and transforms skewed numeric features in a DataFrame.\n",
    "    # Positive skew above 'skew_threshold' is corrected using a log transformation.\n",
    "    # Negative skew below -'skew_threshold' is corrected using a Box-Cox transformation.\n",
    "    # Handles columns with negative or zero values by shifting them before transformation.\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        x = df[col]\n",
    "        skewness = x.skew()\n",
    "\n",
    "        has_neg = (x < 0).any()\n",
    "        has_zero = (x == 0).any()\n",
    "\n",
    "        if has_neg:\n",
    "            min_val = x.min()\n",
    "            df[col] = x + abs(min_val) + 1\n",
    "\n",
    "        if skewness > skew_threshold:\n",
    "            print(f\"Transforming (log) column '{col}' with skewness {skewness:.4f}\")\n",
    "            if has_zero:\n",
    "                df[col] = np.log(df[col] + 1)\n",
    "            else:\n",
    "                df[col] = np.log(df[col])\n",
    "\n",
    "        elif skewness < -skew_threshold:\n",
    "            print(f\"Transforming (Box-Cox) column '{col}' with skewness {skewness:.4f}\")\n",
    "            if has_zero:\n",
    "                transformed, _ = boxcox(df[col] + 1)\n",
    "                df[col] = transformed\n",
    "            else:\n",
    "                transformed, _ = boxcox(df[col])\n",
    "                df[col] = transformed\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b61bf615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_log_boxcox(df, skew_threshold=1):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        x = df[col]\n",
    "        skewness = x.skew()\n",
    "\n",
    "        has_neg = (x < 0).any()\n",
    "        has_zero = (x == 0).any()\n",
    "\n",
    "        if has_neg:\n",
    "            min_val = x.min()\n",
    "            df[col] = x + abs(min_val) + 1\n",
    "\n",
    "        if skewness > skew_threshold:\n",
    "            print(\"PASSEI AQUI +1\")\n",
    "            if has_zero:\n",
    "                df[col] = df[col] + 1\n",
    "                df[col] = np.log(df[col])\n",
    "            else:\n",
    "                df[col] = np.log(df[col])\n",
    "\n",
    "        elif skewness < -skew_threshold:\n",
    "            print(\"PASSEI AQUI -1\")\n",
    "            if has_zero:\n",
    "                df[col] = df[col] + 1\n",
    "                transformed, _ = boxcox(df[col])\n",
    "                df[col] = transformed\n",
    "            else:\n",
    "                transformed, _ = boxcox(df[col])\n",
    "                df[col] = transformed\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51087745",
   "metadata": {},
   "source": [
    "#### Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afd87ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    min_max_scaled = min_max_scaler.fit_transform(df)\n",
    "    \n",
    "    return pd.DataFrame(min_max_scaled, columns=df.columns, index=df.index)\n",
    "\n",
    "def time_fixer(dataset):\n",
    "\n",
    "    df = dataset.copy()\n",
    "\n",
    "    suffixes = (\"_MEAN\", \"_SKEW\", \"_VAR\", \"_KUR\")\n",
    "    stat_columns = [col for col in df.columns if col.endswith(suffixes)]\n",
    "\n",
    "    original_order = df.columns.tolist()\n",
    "\n",
    "    def scale_group(group):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(group[stat_columns])\n",
    "        group[stat_columns] = pd.DataFrame(scaled, columns=stat_columns, index=group.index)\n",
    "        return group\n",
    "\n",
    "    df = df.groupby('SEASON_ID', group_keys=False).apply(scale_group)\n",
    "    df = df[original_order]\n",
    "\n",
    "    dataset_features = df.iloc[:, :-12].copy()\n",
    "\n",
    "    return dataset_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc128e3",
   "metadata": {},
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f74d20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE\n",
    "# Applies UMAP (Uniform Manifold Approximation and Projection) for dimensionality reduction.\n",
    "# Reduces the input DataFrame to 'n_components' dimensions.\n",
    "# 'n_neighbors' controls the local neighborhood size for manifold approximation.\n",
    "# 'min_dist=0.0' preserves more of the global structure (points can be close together).\n",
    "# Returns a NumPy array with the embedded coordinates.\n",
    "\n",
    "def umap_method(df: pd.DataFrame, n_components: int, n_neighbors: int, random_state: int) -> np.ndarray:\n",
    "\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=0.0,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    embedding = reducer.fit_transform(df)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8e5c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap_embedding(embedding: np.ndarray, n_neighbors: int, seed: int):\n",
    "\n",
    "    # Plots 2D and 3D UMAP embeddings of the input data.\n",
    "    # Useful for visualizing high-dimensional data in lower dimensions.\n",
    "\n",
    "    # 2D UMAP embedding\n",
    "    umap_2d = umap.UMAP(\n",
    "        n_components=2,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=0.0,\n",
    "        random_state=seed\n",
    "    )\n",
    "    umap_emb_2d = umap_2d.fit_transform(embedding)\n",
    "\n",
    "    plt.switch_backend('Agg')  # NOTE: Ensures plots can be saved without a display (headless)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(umap_emb_2d[:, 0], umap_emb_2d[:, 1], s=10, c='green')\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('UMAP_2D.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 3D UMAP embedding\n",
    "    umap_3d = umap.UMAP(\n",
    "        n_components=3,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=0.0,\n",
    "        random_state=seed\n",
    "    )\n",
    "    umap_emb_3d = umap_3d.fit_transform(embedding)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(umap_emb_3d[:, 0], umap_emb_3d[:, 1], umap_emb_3d[:, 2], s=10, c='green')\n",
    "    ax.set_xlabel(\"UMAP 1\")\n",
    "    ax.set_ylabel(\"UMAP 2\")\n",
    "    ax.set_zlabel(\"UMAP 3\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('UMAP_3D.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d94cc",
   "metadata": {},
   "source": [
    "#### Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7cffc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_method(embedding: np.ndarray, n_clusters: int, seed: int, plot: bool):\n",
    "\n",
    "    # Performs KMeans clustering on the provided embedding.\n",
    "    # Returns cluster labels, average silhouette score, indices of points with negative silhouette, indices of points closest to each cluster center, and inertia.\n",
    "    # Useful for evaluating cluster quality and detecting potential outliers.\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=seed)\n",
    "    labels = kmeans.fit_predict(embedding)\n",
    "\n",
    "    score = silhouette_score(embedding, labels)\n",
    "    silhouette_vals = silhouette_samples(embedding, labels)\n",
    "    low_scores = np.where(silhouette_vals < 0)[0]  # points with negative silhouette\n",
    "\n",
    "    distances = euclidean_distances(embedding, kmeans.cluster_centers_)\n",
    "    closest_indices = distances.argmin(axis=0)  # closest point to each cluster center\n",
    "\n",
    "    if plot:\n",
    "        plot_2d_tsne_embedding(\n",
    "            embedding,\n",
    "            500,\n",
    "            \"k_means_outliers\",\n",
    "            seed,\n",
    "            labels,\n",
    "            kmeans.cluster_centers_\n",
    "        )\n",
    "\n",
    "    inertia = kmeans.inertia_\n",
    "\n",
    "    return labels, score, low_scores, closest_indices, inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98408f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Computes and plots silhouette scores for different numbers of clusters.\n",
    "# Runs KMeans multiple times per cluster count to account for randomness.\n",
    "# Plots mean silhouette score with a shaded 95% confidence interval.\n",
    "# Useful for identifying the optimal number of clusters.\n",
    "\n",
    "def plot_silhouette_analysis(\n",
    "    embedding: np.ndarray,\n",
    "    cluster_range=range(2, 11),\n",
    "    n_runs=10,\n",
    "    filename='silhouette_score_clusters.png'\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    silhouette_results = []\n",
    "\n",
    "    for k in cluster_range:\n",
    "        silhouette_scores = []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            seed = random.randint(0, 2**32 - 1)\n",
    "            labels, score, outliers, closest_pts, inertia = kmeans_method(\n",
    "                embedding=embedding, n_clusters=k, seed=seed, plot=False\n",
    "            )\n",
    "            silhouette_scores.append(score)\n",
    "\n",
    "        mean_val = np.mean(silhouette_scores)\n",
    "        std_val = np.std(silhouette_scores, ddof=1)\n",
    "        ci95 = 1.96 * std_val / np.sqrt(n_runs)\n",
    "\n",
    "        print(f\"Clusters={k}, Mean Silhouette={mean_val:.4f}, 95% CI ±{ci95:.4f}\")\n",
    "\n",
    "        silhouette_results.append({\n",
    "            'k': k,\n",
    "            'mean': mean_val,\n",
    "            'ci95': ci95\n",
    "        })\n",
    "\n",
    "    df_silhouette = pd.DataFrame(silhouette_results)\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.lineplot(\n",
    "        data=df_silhouette,\n",
    "        x='k',\n",
    "        y='mean',\n",
    "        marker='o',\n",
    "        color='blue',\n",
    "        linewidth=2,\n",
    "        linestyle='-',\n",
    "        label='Mean Silhouette Score'\n",
    "    )\n",
    "\n",
    "    for idx, row in df_silhouette.iterrows():\n",
    "        plt.fill_betweenx(\n",
    "            [row['mean'] - row['ci95'], row['mean'] + row['ci95']],\n",
    "            row['k'] - 0.1, row['k'] + 0.1,\n",
    "            color='blue',\n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "    line = mlines.Line2D([], [], color='blue', marker='o', linestyle='-', label='Mean')\n",
    "    rectangle = mpatches.Patch(color='blue', alpha=0.2, label='Confidence Interval')\n",
    "    plt.legend(handles=[line, rectangle], loc='best')\n",
    "\n",
    "    plt.xlabel(r'\\#\\ Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.xticks(df_silhouette['k'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return df_silhouette\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "264651f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Computes and plots the KMeans inertia (within-cluster sum of squares) for a range of cluster numbers.\n",
    "# Runs KMeans multiple times per cluster count to reduce randomness effects.\n",
    "# Plots mean inertia with a shaded area representing the 95% confidence interval.\n",
    "\n",
    "def plot_inertia_analysis(\n",
    "    embedding: np.ndarray,\n",
    "    cluster_range=range(2, 10),\n",
    "    n_runs=30,\n",
    "    filename='inertia_clusters.png'\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    inertia_results = []\n",
    "\n",
    "    for k in cluster_range:\n",
    "        inertia_scores = []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            seed = random.randint(0, 2**32 - 1)\n",
    "            labels, score, outliers, cs, inertia = kmeans_method(\n",
    "                embedding=embedding,\n",
    "                n_clusters=k,\n",
    "                seed=seed,\n",
    "                plot=False\n",
    "            )\n",
    "            inertia_scores.append(inertia)\n",
    "\n",
    "        print(k)\n",
    "        print(np.mean(inertia_scores))\n",
    "        inertia_results.append({\n",
    "            'k': k,\n",
    "            'mean': np.mean(inertia_scores),\n",
    "            'std': np.std(inertia_scores, ddof=1)\n",
    "        })\n",
    "\n",
    "    df_inertia = pd.DataFrame(inertia_results)\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.lineplot(\n",
    "        data=df_inertia, x='k', y='mean', marker='o', color='green',\n",
    "        linewidth=2, linestyle='-', label='Média da Inércia'\n",
    "    )\n",
    "\n",
    "    for idx, row in df_inertia.iterrows():\n",
    "        plt.fill_betweenx(\n",
    "            [row['mean'] - row['std'], row['mean'] + row['std']],\n",
    "            row['k'] - 0.1, row['k'] + 0.1,\n",
    "            color='green', alpha=0.2\n",
    "        )\n",
    "\n",
    "    line = mlines.Line2D([], [], color='green', marker='o', linestyle='-', label='Mean')\n",
    "    rectangle = mpatches.Patch(color='green', alpha=0.2, label='Confidence Interval')\n",
    "\n",
    "    plt.legend(handles=[line, rectangle], loc='best')\n",
    "\n",
    "    plt.xlabel(r'\\#\\ Clusters')\n",
    "    plt.ylabel('Inertia (WCSS)')\n",
    "    plt.xticks(df_inertia['k'])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return df_inertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c06bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Generates a 'blade-style' silhouette plot for KMeans clustering.\n",
    "# Each cluster's silhouette scores are sorted and plotted as horizontal 'blades'.\n",
    "# Helps visualize cohesion and separation of clusters.\n",
    "# A vertical red dashed line indicates the average silhouette score.\n",
    "\n",
    "def plot_silhouette_blades(embedding: np.ndarray, n_clusters: int, seed: int):\n",
    "\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=seed)\n",
    "    labels = kmeans.fit_predict(embedding)\n",
    "\n",
    "    silhouette_vals = silhouette_samples(embedding, labels)\n",
    "    silhouette_avg = silhouette_score(embedding, labels)\n",
    "    print(f\"Average Silhouette Score: {silhouette_avg:.4f}\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    ax.set_ylim([0, len(embedding)])\n",
    "\n",
    "    y_upper = len(embedding)\n",
    "    for i in range(n_clusters):\n",
    "        cluster_vals = silhouette_vals[labels == i]\n",
    "        cluster_vals.sort()\n",
    "        size = cluster_vals.shape[0]\n",
    "        y_lower = y_upper - size\n",
    "\n",
    "        # Color using a spectral colormap\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_vals, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Cluster number label\n",
    "        ax.text(-0.05, y_lower + 0.5 * size, str(i + 1))\n",
    "\n",
    "        y_upper = y_lower\n",
    "\n",
    "    ax.set_xlabel(\"Silhouette Score\")\n",
    "    ax.set_ylabel(\"Clusters\", labelpad=15)\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", label=\"Average Silhouette\")\n",
    "    ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    ax.set_yticks([])\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"silhouette_analysis_{n_clusters}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "408ef251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# Prepares feature and metadata DataFrames for analysis.\n",
    "# Resets indices, concatenates features and metadata, and scales features to [0,1] using MinMaxScaler.\n",
    "# If cluster labels are provided, they are added as a 'CLUSTER' column to all returned DataFrames.\n",
    "\n",
    "def formatted_data_to_analysis(features: pd.DataFrame, metadata: pd.DataFrame, labels=None):\n",
    "    \n",
    "    features = features.reset_index(drop=True)\n",
    "    metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "    combined = pd.concat([features, metadata], axis=1)\n",
    "\n",
    "    features_to_scale = features.copy()\n",
    "    \n",
    "    # Max-Min preparation is used on GINI plots, where we need scales in the same proportion\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled_array = scaler.fit_transform(features_to_scale)\n",
    "    features_scaled = pd.DataFrame(features_scaled_array, columns=features.columns)\n",
    "\n",
    "    if labels is not None:\n",
    "        labels = np.array(labels)\n",
    "        features[\"CLUSTER\"] = labels\n",
    "        combined[\"CLUSTER\"] = labels\n",
    "        features_scaled[\"CLUSTER\"] = labels\n",
    "\n",
    "    return features, combined, features_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c3783",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2a9344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Choose the clusters colors\n",
    "\n",
    "colors=['#97d8b2','#9e7b9b','#e7bb41','#531253','#ef3054']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ec7a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Plots the size of each cluster by comparing:\n",
    "#   1. The total number of rows assigned to each cluster.\n",
    "#   2. The number of unique players (PLAYER_ID) per cluster.\n",
    "# Produces a side-by-side bar chart for comparison.\n",
    "# Cluster labels from KMeans usually start at 0, but the x-axis is shifted (+1) for readability.\n",
    "\n",
    "def cluster_size(df: pd.DataFrame, title: str= \"cluster_size\"):\n",
    "\n",
    "    groups = df.groupby('CLUSTER')[[\"PLAYER_ID\"]]\n",
    "\n",
    "    unique_players_per_cluster = groups.nunique()\n",
    "\n",
    "    # Count total rows (including duplicates) per cluster\n",
    "    total_players_per_cluster = groups.size()\n",
    "\n",
    "    clusters = total_players_per_cluster.index\n",
    "    width = 0.3\n",
    "\n",
    "    r1 = np.arange(len(clusters))\n",
    "    r2 = [x + width for x in r1]\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.bar(r1, total_players_per_cluster.values, color='#A0ACAD', width=width, label='Total')\n",
    "    plt.bar(r2, unique_players_per_cluster['PLAYER_ID'].values, color='#97D8B2', width=width, label='Unique')\n",
    "\n",
    "    plt.xlabel('Clusters')\n",
    "    plt.ylabel(r\"\\# Players\")\n",
    "    plt.xticks([r + width/2 for r in range(len(clusters))], clusters + 1)\n",
    "\n",
    "    plt.legend(\n",
    "        bbox_to_anchor=(0.5, 1),\n",
    "        loc='upper right',\n",
    "        ncol=2,\n",
    "        handlelength=1,\n",
    "        columnspacing=0.5\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b626378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# Plots the evolution of cluster membership counts over seasons.\n",
    "# For each cluster, plots a time series showing how many players belong to it each season.\n",
    "# Cluster indices are incremented by +1 for readability.\n",
    "\n",
    "def cluster_members_by_year(df: pd.DataFrame, title: str= \"cluster_members_by_year\"):\n",
    "\n",
    "    cluster_year_counts = df.groupby(['CLUSTER', 'SEASON_ID']).size().reset_index(name='Count')\n",
    "    clusters = cluster_year_counts['CLUSTER'].unique()\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        cluster_data = cluster_year_counts[cluster_year_counts['CLUSTER'] == cluster]\n",
    "        plt.plot(\n",
    "            cluster_data['SEASON_ID'],\n",
    "            cluster_data['Count'],\n",
    "            label=f'Cluster {cluster + 1}',\n",
    "            color=colors[idx % len(colors)]\n",
    "        )\n",
    "\n",
    "    plt.xticks(fontsize=6, rotation=90)\n",
    "    plt.xlabel('Season')\n",
    "    plt.ylabel(r'\\# Players')\n",
    "    plt.legend(\n",
    "        loc=\"upper left\",\n",
    "        ncol=2,\n",
    "        fontsize=8\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f6caf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# Plots cumulative cluster membership over years.\n",
    "# Groups dataset by cluster and season (SEASON_ID).\n",
    "# Computes cumulative player count per cluster across seasons.\n",
    "# Each cluster’s curve shows how many players joined cumulatively up to each year.\n",
    "# X-axis uses the starting year of each season for better readability.\n",
    "\n",
    "def cluster_members_total(df: pd.DataFrame, title: str= \"accumulate_cluster_by_year\"):\n",
    "\n",
    "    cluster_year_counts = df.groupby(['CLUSTER', 'SEASON_ID']).size().reset_index(name='Count')\n",
    "\n",
    "    cluster_year_counts = cluster_year_counts.sort_values(['SEASON_ID', 'CLUSTER'])\n",
    "\n",
    "    cluster_year_counts['Cumulative_Count'] = cluster_year_counts.groupby('CLUSTER')['Count'].cumsum()\n",
    "\n",
    "    cluster_year_counts['Year'] = cluster_year_counts['SEASON_ID'].str.split('-').str[0].astype(int)\n",
    "\n",
    "    clusters = cluster_year_counts['CLUSTER'].unique()\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        cluster_data = cluster_year_counts[cluster_year_counts['CLUSTER'] == cluster]\n",
    "        plt.plot(\n",
    "            cluster_data['Year'],\n",
    "            cluster_data['Cumulative_Count'],\n",
    "            label=f'Cluster {cluster + 1}',\n",
    "            color=colors[idx % len(colors)]\n",
    "        )\n",
    "\n",
    "    plt.xlabel('Year', loc='center')\n",
    "    plt.ylabel(r'\\# Players')\n",
    "\n",
    "    plt.xticks(fontsize=8, rotation=90)\n",
    "    plt.yticks(fontsize=8)\n",
    "\n",
    "    plt.legend(\n",
    "        loc=\"upper left\",\n",
    "        ncol=2,\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bd740ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Plots bar chart of individual awards (MVP, DPOY, MIP, 6MOY) by cluster.\n",
    "# Counts how many players in each cluster won each award.\n",
    "# Uses grouped bar plot for side-by-side comparison.\n",
    "# Each award type has a distinct color.\n",
    "\n",
    "def awards_by_cluster(df: pd.DataFrame, title: str= \"cluster_awards\"):\n",
    "\n",
    "    total_clusters = df[\"CLUSTER\"].nunique()\n",
    "\n",
    "    dpoy_count_per_cluster = (\n",
    "        df[df[\"DPOY\"] == 1]\n",
    "        .groupby(\"CLUSTER\")[\"DPOY\"]\n",
    "        .count()\n",
    "        .reindex(range(total_clusters), fill_value=0)\n",
    "    )\n",
    "\n",
    "    mip_count = (\n",
    "        df[df[\"MIP\"] == 1]\n",
    "        .groupby(\"CLUSTER\")[\"MIP\"]\n",
    "        .count()\n",
    "        .reindex(range(total_clusters), fill_value=0)\n",
    "    )\n",
    "\n",
    "    mvp_count = (\n",
    "        df[df[\"MVP\"] == 1]\n",
    "        .groupby(\"CLUSTER\")[\"MVP\"]\n",
    "        .count()\n",
    "        .reindex(range(total_clusters), fill_value=0)\n",
    "    )\n",
    "\n",
    "    six_count = (\n",
    "        df[df[\"SMOY\"] == 1]\n",
    "        .groupby(\"CLUSTER\")[\"SMOY\"]\n",
    "        .count()\n",
    "        .reindex(range(total_clusters), fill_value=0)\n",
    "    )\n",
    "\n",
    "    clusters = [1, 2, 3, 4, 5]\n",
    "    width = 0.15\n",
    "\n",
    "    r1 = np.arange(len(clusters))\n",
    "    r2 = [x + width for x in r1]\n",
    "    r3 = [x + width * 2 for x in r1]\n",
    "    r4 = [x + width * 3 for x in r1]\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "\n",
    "    plt.bar(r1, mvp_count.values, color='#531253', width=width, label='MVP')\n",
    "    plt.bar(r2, dpoy_count_per_cluster.values, color='#e09891', width=width, label='DPOY')\n",
    "    plt.bar(r3, mip_count.values, color='#a0acad', width=width, label='MIP')\n",
    "    plt.bar(r4, six_count.values, color='#97d8b2', width=width, label='6MOY')\n",
    "\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Individual Awards')\n",
    "\n",
    "    plt.xticks([r + width * 1.5 for r in range(len(clusters))], clusters)\n",
    "\n",
    "    plt.legend(loc='upper left', fontsize=6, ncol=4, handlelength=0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae119b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE\n",
    "# Computes Gini index and Lorenz curve utilities.\n",
    "# gini(arr): returns the Gini coefficient for inequality measurement.\n",
    "# lorenz(arr): returns cumulative Lorenz curve values.\n",
    "\n",
    "def gini(arr):\n",
    "    arr = np.sort(arr)          # NOTE: Sort values\n",
    "    arr = np.clip(arr, 0, None) # NOTE: Clip negatives (Gini not defined for < 0)\n",
    "\n",
    "    count = arr.size\n",
    "    coefficient = 2 / count\n",
    "    indexes = np.arange(1, count + 1)\n",
    "    weighted_sum = (indexes * arr).sum()\n",
    "    total = arr.sum()\n",
    "\n",
    "    if total == 0:\n",
    "        return 0  # NOTE: Avoid division by zero\n",
    "\n",
    "    constant = (count + 1) / count\n",
    "    return coefficient * weighted_sum / total - constant\n",
    "\n",
    "\n",
    "def lorenz(arr):\n",
    "    # NOTE: Builds Lorenz curve (cumulative distribution)\n",
    "    scaled_prefix_sum = arr.cumsum() / arr.sum()\n",
    "    return np.insert(scaled_prefix_sum, 0, 0)  # NOTE: Ensure curve starts at 0\n",
    "\n",
    "\n",
    "# NOTE:\n",
    "# Computes average Gini per variable across clusters and ranks variables.\n",
    "# Groups dataset by CLUSTER.\n",
    "# Computes averages Gini values across clusters.\n",
    "# Returns top N variables with highest mean inequality.\n",
    "\n",
    "def gini_most(df: pd.DataFrame, num_vars: int):\n",
    "    gini_scores = {}\n",
    "    grouped = df.groupby('CLUSTER')\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column != 'CLUSTER' and 'MEAN' in column:\n",
    "            gini_index_per_cluster = {}\n",
    "            for name, group in grouped:\n",
    "                sorted_values = group[column].sort_values().tolist()\n",
    "                gini_index_per_cluster[name] = gini(np.array(sorted_values))\n",
    "            gini_scores[column] = gini_index_per_cluster\n",
    "\n",
    "    differences = {}\n",
    "    for var, values in gini_scores.items():\n",
    "        values_list = list(values.values())\n",
    "        diff = np.mean(values_list)\n",
    "        differences[var] = diff\n",
    "\n",
    "    sorted_vars = sorted(differences.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_10_vars = sorted_vars[:num_vars]\n",
    "    features = []\n",
    "\n",
    "    for var, diff in top_10_vars:\n",
    "        print(f'Feature: {var}, Gini Index: {diff}')\n",
    "        features.append(var)\n",
    "\n",
    "    df_top_10 = pd.DataFrame(top_10_vars, columns=['Features', 'Mean'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=df_top_10.values,\n",
    "        colLabels=df_top_10.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center'\n",
    "    )\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33b5726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# Plots mean + 95% confidence intervals of a feature per cluster.\n",
    "# For each cluster: computes mean, SEM, and 95% CI.\n",
    "# Displays as bar plot with error bars.\n",
    "\n",
    "def ginix_diference_plot(df: pd.DataFrame, column: str, title: str):\n",
    "\n",
    "    grouped = df.groupby('CLUSTER')[column]\n",
    "    graph_data = []\n",
    "\n",
    "    for cluster, group in grouped:\n",
    "        mean = np.mean(group)          \n",
    "        sem = stats.sem(group)          \n",
    "        df = len(group) - 1            \n",
    "\n",
    "        if df > 0:\n",
    "            interval = stats.t.interval(\n",
    "                confidence=0.95,\n",
    "                df=df,\n",
    "                loc=mean,\n",
    "                scale=sem\n",
    "            )\n",
    "        else:\n",
    "            interval = (mean, mean) \n",
    "\n",
    "        graph_data.append({\n",
    "            'cluster': cluster,\n",
    "            'mean': mean,\n",
    "            'lower': interval[0],\n",
    "            'upper': interval[1]\n",
    "        })\n",
    "\n",
    "    graph_df = pd.DataFrame(graph_data).set_index('cluster')\n",
    "    x_vals = graph_df.index + 1\n",
    "\n",
    "    def decimal_format(x, pos):\n",
    "        return f'{x:.1f}'\n",
    "    formatter = FuncFormatter(decimal_format)\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "\n",
    "    plt.bar(x=x_vals, height=graph_df['mean'], color='red', alpha=0.7)\n",
    "\n",
    "    plt.errorbar(\n",
    "        x=x_vals,\n",
    "        y=graph_df['mean'],\n",
    "        yerr=[graph_df['mean'] - graph_df['lower'],\n",
    "              graph_df['upper'] - graph_df['mean']],\n",
    "        fmt='none',\n",
    "        ecolor='black',\n",
    "        capsize=3,\n",
    "        elinewidth=0.8\n",
    "    )\n",
    "\n",
    "    plt.xticks(x_vals)\n",
    "    plt.xlabel('Clusters')\n",
    "    plt.ylabel(column)\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f451a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotradar_columns = [\"FG3M_MEAN\", \"LONG_MID_RANGE_SHOT_M_MEAN\", \"BLK_MEAN\", \"MID_RANGE_SHOT_U_MEAN\",\n",
    "           \"AST_MEAN\", \"FTU_MEAN\", \"OREB_MEAN\", \"CLUSTER\"]\n",
    "\n",
    "# NOTE: \n",
    "# Plots radar charts for the mean values of selected features per cluster.\n",
    "# Each subplot corresponds to a cluster. The radar shows normalized mean values for the given features.\n",
    "# 'CLUSTER' column in the dataset.\n",
    "\n",
    "def plotradar(data: pd.DataFrame, colors=colors, columns=plotradar_columns, title: str = \"plot_radar\"):\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[columns]\n",
    "\n",
    "    clusters = [0, 1, 2, 3, 4]\n",
    "    df_filtered = df[df[\"CLUSTER\"].isin(clusters)]\n",
    "    clusters = df_filtered[\"CLUSTER\"].unique()\n",
    "    clusters.sort()\n",
    "\n",
    "    num_clusters = len(clusters)\n",
    "    fig, axes = plt.subplots(\n",
    "        1, num_clusters,\n",
    "        figsize=(num_clusters * 1.5, 1.5),\n",
    "        subplot_kw={'polar': True}\n",
    "    )\n",
    "\n",
    "    if num_clusters == 1:\n",
    "        axes = [axes]  # NOTE: Ensure axes is iterable for single cluster\n",
    "\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        cluster_data = df[df[\"CLUSTER\"] == cluster].drop(columns=[\"CLUSTER\"])\n",
    "\n",
    "        if cluster_data.empty:\n",
    "            print(f\"Cluster {cluster} has no data.\")\n",
    "            continue\n",
    "\n",
    "        N = len(cluster_data.columns)  # NOTE: Number of metrics/features\n",
    "        metrics = list(range(1, N + 1))\n",
    "\n",
    "        angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # NOTE: Close the radar polygon\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.set_theta_offset(np.pi / 2)\n",
    "        ax.set_theta_direction(-1)\n",
    "\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels([str(m) for m in metrics], fontsize=10)\n",
    "\n",
    "        ax.set_rlabel_position(0)\n",
    "        ax.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "        ax.set_yticklabels([\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], color=\"grey\", fontsize=8)\n",
    "        ax.set_ylim(0, 0.5)\n",
    "\n",
    "        mean_values = cluster_data.mean().values.flatten().tolist()\n",
    "        mean_values += mean_values[:1]\n",
    "\n",
    "        ax.plot(angles, mean_values, linewidth=1, linestyle=\"solid\", color=colors[i])\n",
    "        ax.fill(angles, mean_values, alpha=0.2, color=colors[i])\n",
    "\n",
    "        for label, angle in zip(ax.get_xticklabels(), angles[:-1]):\n",
    "            x_offset = 0.2\n",
    "            y_offset = 0.2\n",
    "            label.set_position((angle, x_offset))\n",
    "            label.set_fontsize(10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04fa879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# Computes cluster migration percentages for players across seasons.\n",
    "# 'Pct_Leaving' = % of players leaving the origin cluster to a specific destination cluster.\n",
    "# 'Pct_Total' = % of total migrations represented by this specific transfer.\n",
    "\n",
    "def analyze_cluster_migration_percentages(df: pd.DataFrame, season_ids: list, n_clusters: int) -> pd.DataFrame:\n",
    "\n",
    "    years_data = df[df[\"SEASON_ID\"].isin(season_ids)].copy()\n",
    "\n",
    "    years_data = years_data.sort_values(by=[\"PLAYER_ID\", \"SEASON_ID\"])\n",
    "\n",
    "    years_data[\"NEXT_CLUSTER\"] = years_data.groupby(\"PLAYER_ID\")[\"CLUSTER\"].shift(-1)\n",
    "\n",
    "    migration_year = years_data.dropna(subset=[\"NEXT_CLUSTER\"])\n",
    "    migration_year = migration_year[migration_year[\"CLUSTER\"] != migration_year[\"NEXT_CLUSTER\"]]\n",
    "\n",
    "    migration_counts = (\n",
    "        migration_year\n",
    "        .groupby([\"CLUSTER\", \"NEXT_CLUSTER\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"Transfers\")\n",
    "    )\n",
    "\n",
    "    all_pairs = pd.DataFrame(\n",
    "        [(i, j) for i in range(n_clusters) for j in range(n_clusters) if i != j],\n",
    "        columns=[\"FROM_CLUSTER\", \"TO_CLUSTER\"]\n",
    "    )\n",
    "\n",
    "    migration_counts = pd.merge(\n",
    "        all_pairs,\n",
    "        migration_counts,\n",
    "        left_on=[\"FROM_CLUSTER\", \"TO_CLUSTER\"],\n",
    "        right_on=[\"CLUSTER\", \"NEXT_CLUSTER\"],\n",
    "        how=\"left\"\n",
    "    ).fillna({\"Transfers\": 0})\n",
    "\n",
    "    migration_counts = migration_counts.drop(columns=[\"CLUSTER\", \"NEXT_CLUSTER\"])\n",
    "\n",
    "    total_outgoing = migration_counts.groupby(\"FROM_CLUSTER\")[\"Transfers\"].sum().reset_index()\n",
    "    total_outgoing.rename(columns={\"Transfers\": \"Total_Leaving\"}, inplace=True)\n",
    "\n",
    "    total_transfers = migration_counts[\"Transfers\"].sum()\n",
    "\n",
    "    migration_counts = migration_counts.merge(total_outgoing, on=\"FROM_CLUSTER\", how=\"left\")\n",
    "\n",
    "    migration_counts[\"Pct_Leaving\"] = migration_counts.apply(\n",
    "        lambda row: (row[\"Transfers\"] / row[\"Total_Leaving\"] * 100) if row[\"Total_Leaving\"] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    migration_counts[\"Pct_Total\"] = migration_counts.apply(\n",
    "        lambda row: (row[\"Transfers\"] / total_transfers * 100) if total_transfers > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    migration_counts[\"FROM_CLUSTER\"] = migration_counts[\"FROM_CLUSTER\"] + 1\n",
    "    migration_counts[\"TO_CLUSTER\"] = migration_counts[\"TO_CLUSTER\"] + 1\n",
    "\n",
    "    return migration_counts[[\"FROM_CLUSTER\", \"TO_CLUSTER\", \"Pct_Leaving\", \"Pct_Total\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19c576cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# Plots the distribution of player positions across clusters.\n",
    "# Groups similar positions into general categories: Center, Forward, Guard.\n",
    "# Uses a grouped bar chart to show counts per cluster for each position.\n",
    "\n",
    "def plot_players_position_by_cluster(df: pd.DataFrame, title: str = \"player_position_by_cluster\"):\n",
    "\n",
    "    df[\"POSITION\"] = df[\"POSITION\"].replace([\"Center-Forward\"], \"Center\")\n",
    "    df[\"POSITION\"] = df[\"POSITION\"].replace([\"Forward-Center\", \"Forward-Guard\"], \"Forward\")\n",
    "    df[\"POSITION\"] = df[\"POSITION\"].replace([\"Guard-Forward\"], \"Guard\")\n",
    "\n",
    "    positions = df.groupby(['CLUSTER', 'POSITION']).size().unstack(fill_value=0)\n",
    "\n",
    "    clusters = [1, 2, 3, 4, 5]\n",
    "\n",
    "    center_counts = positions[\"Center\"].values\n",
    "    forward_counts = positions[\"Forward\"].values\n",
    "    guard_counts = positions[\"Guard\"].values\n",
    "\n",
    "    width = 0.15\n",
    "    x = np.arange(len(clusters))\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "\n",
    "    plt.bar(x - width, center_counts, width=width, color='#531253', label='Center')\n",
    "    plt.bar(x, forward_counts, width=width, color='#e09891', label='Forward')\n",
    "    plt.bar(x + width, guard_counts, width=width, color='#e7bb41', label='Guard')\n",
    "\n",
    "    plt.xlabel('Clusters')\n",
    "    plt.ylabel('# Players')\n",
    "    plt.xticks(x, clusters)\n",
    "    plt.legend(loc='upper left', fontsize=8, ncol=3, handlelength=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_court(ax=None, color='black', lw=2, outer_lines=False):\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False)\n",
    "\n",
    "    backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color)\n",
    "\n",
    "    outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color,\n",
    "                          fill=False)\n",
    "\n",
    "    inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color,\n",
    "                          fill=False)\n",
    "\n",
    "    top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180,\n",
    "                         linewidth=lw, color=color, fill=False)\n",
    "\n",
    "    bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0,\n",
    "                            linewidth=lw, color=color, linestyle='dashed')\n",
    "\n",
    "    restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw,\n",
    "                     color=color)\n",
    "\n",
    "    corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw,\n",
    "                               color=color)\n",
    "    corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color)\n",
    "\n",
    "    three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw,\n",
    "                    color=color)\n",
    "\n",
    "    center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0,\n",
    "                           linewidth=lw, color=color)\n",
    "    center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0,\n",
    "                           linewidth=lw, color=color)\n",
    "\n",
    "    court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw,\n",
    "                      bottom_free_throw, restricted, corner_three_a,\n",
    "                      corner_three_b, three_arc, center_outer_arc,\n",
    "                      center_inner_arc]\n",
    "\n",
    "    if outer_lines:\n",
    "        outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw,\n",
    "                                color=color, fill=False)\n",
    "        court_elements.append(outer_lines)\n",
    "\n",
    "    for element in court_elements:\n",
    "        ax.add_patch(element)\n",
    "\n",
    "    return ax\n",
    "\n",
    "# NOTE: \n",
    "# Plots a shot map for a given player.\n",
    "# Made shots are shown as green circles, missed shots as red Xs.\n",
    "# Accepts any player_id and output filename/title.\n",
    "\n",
    "def plot_players_shot_map(shot_df: pd.DataFrame, player_id: int, title: str = \"shot_map\"):\n",
    "\n",
    "    player_shots = shot_df[shot_df[\"PLAYER_ID\"] == player_id]\n",
    "\n",
    "    plt.figure(figsize=(3.5, 4))\n",
    "\n",
    "    for _, row in player_shots.iterrows():\n",
    "        if row[\"SHOT_MADE_FLAG\"] == 1:  # Made shot\n",
    "            plt.scatter(row['LOC_X'], row['LOC_Y'], color='#76b947', marker='o')  # Green circle\n",
    "        else:  # Missed shot\n",
    "            plt.scatter(row['LOC_X'], row['LOC_Y'], color='#ba0f30', marker='x')  # Red X\n",
    "\n",
    "    draw_court()\n",
    "\n",
    "    plt.xlim(-250, 250)\n",
    "    plt.ylim(422.5, -47.5)\n",
    "\n",
    "    plt.gca().set_xticks([])\n",
    "    plt.gca().set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
